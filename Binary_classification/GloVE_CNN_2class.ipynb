{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Feb 11 12:29:48 2019\n",
    "\n",
    "@author: SLab\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import keras.callbacks\n",
    "#import sys\n",
    "import os\n",
    "import pandas\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dropout\n",
    "#import keras\n",
    "from scipy import interp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from subprocess import check_output\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn import cross_validation\n",
    "\n",
    "import os, re, csv, math, codecs\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import time\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def auroc(y_true, y_pred):\n",
    "    return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "# auc = roc_auc_score(testy, yhat_probs)\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "def kappa(y_true, y_pred):\n",
    "    cohen_kappa_score(y_true, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "443it [00:00, 4401.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111052it [00:20, 5490.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 111052 word vectors\n",
      "num train:  9518\n",
      "num test:  520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▌                                                                         | 435/9518 [00:00<00:02, 4322.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing train data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9518/9518 [00:00<00:00, 9974.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 520/520 [00:00<00:00, 55392.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing input data...\n",
      "dictionary size:  25519\n",
      "preparing embedding matrix...\n",
      "number of null word embeddings: 12772\n",
      "sample words not found:  ['gottron' 'event2' 'planarity' 'stipulations' 'generalizeâ' 'diminum'\n",
      " 'schuhmann' 'binot' 'it13' 'entence']\n",
      "training CNN ...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 213, 300)          7656300   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 213, 64)           134464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 106, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 106, 64)           28736     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,821,646\n",
      "Trainable params: 165,346\n",
      "Non-trainable params: 7,656,300\n",
      "_________________________________________________________________\n",
      "Train on 7614 samples, validate on 1904 samples\n",
      "Epoch 1/100\n",
      " - 14s - loss: 1.3291 - accuracy: 0.5114 - precision: 0.5107 - recall: 0.4980 - f1: 0.5037 - val_loss: 0.6830 - val_accuracy: 0.8133 - val_precision: 0.8286 - val_recall: 0.7804 - val_f1: 0.8036\n",
      "Epoch 2/100\n",
      " - 9s - loss: 1.2976 - accuracy: 0.5823 - precision: 0.5795 - recall: 0.5972 - f1: 0.5881 - val_loss: 0.7055 - val_accuracy: 0.6851 - val_precision: 0.7082 - val_recall: 0.6149 - val_f1: 0.6582\n",
      "Epoch 3/100\n",
      " - 9s - loss: 1.2706 - accuracy: 0.5347 - precision: 0.5380 - recall: 0.5177 - f1: 0.5272 - val_loss: 0.6504 - val_accuracy: 0.8072 - val_precision: 0.8047 - val_recall: 0.7998 - val_f1: 0.8022\n",
      "Epoch 4/100\n",
      " - 9s - loss: 1.2425 - accuracy: 0.5684 - precision: 0.5680 - recall: 0.5839 - f1: 0.5756 - val_loss: 0.6521 - val_accuracy: 0.7692 - val_precision: 0.7685 - val_recall: 0.7609 - val_f1: 0.7647\n",
      "Epoch 5/100\n",
      " - 9s - loss: 1.2135 - accuracy: 0.6396 - precision: 0.6363 - recall: 0.6491 - f1: 0.6426 - val_loss: 0.6758 - val_accuracy: 0.6746 - val_precision: 0.6909 - val_recall: 0.6195 - val_f1: 0.6532\n",
      "Epoch 6/100\n",
      " - 9s - loss: 1.1803 - accuracy: 0.6177 - precision: 0.6181 - recall: 0.6179 - f1: 0.6178 - val_loss: 0.6239 - val_accuracy: 0.7610 - val_precision: 0.7592 - val_recall: 0.7577 - val_f1: 0.7584\n",
      "Epoch 7/100\n",
      " - 9s - loss: 1.1383 - accuracy: 0.6430 - precision: 0.6398 - recall: 0.6541 - f1: 0.6467 - val_loss: 0.5903 - val_accuracy: 0.7841 - val_precision: 0.7798 - val_recall: 0.7846 - val_f1: 0.7822\n",
      "Epoch 8/100\n",
      " - 9s - loss: 1.1126 - accuracy: 0.6826 - precision: 0.6759 - recall: 0.7001 - f1: 0.6876 - val_loss: 0.6186 - val_accuracy: 0.7395 - val_precision: 0.7390 - val_recall: 0.7323 - val_f1: 0.7356\n",
      "Epoch 9/100\n",
      " - 9s - loss: 1.0754 - accuracy: 0.6912 - precision: 0.6874 - recall: 0.7021 - f1: 0.6945 - val_loss: 0.6007 - val_accuracy: 0.7529 - val_precision: 0.7524 - val_recall: 0.7420 - val_f1: 0.7471\n",
      "Epoch 10/100\n",
      " - 9s - loss: 1.0326 - accuracy: 0.6997 - precision: 0.6950 - recall: 0.7116 - f1: 0.7031 - val_loss: 0.5731 - val_accuracy: 0.7739 - val_precision: 0.7771 - val_recall: 0.7550 - val_f1: 0.7658\n",
      "Epoch 11/100\n",
      " - 9s - loss: 0.9949 - accuracy: 0.7423 - precision: 0.7346 - recall: 0.7582 - f1: 0.7461 - val_loss: 0.5812 - val_accuracy: 0.7482 - val_precision: 0.7491 - val_recall: 0.7300 - val_f1: 0.7394\n",
      "Epoch 12/100\n",
      " - 9s - loss: 0.9678 - accuracy: 0.7323 - precision: 0.7274 - recall: 0.7454 - f1: 0.7362 - val_loss: 0.4900 - val_accuracy: 0.8272 - val_precision: 0.8307 - val_recall: 0.8118 - val_f1: 0.8211\n",
      "Epoch 13/100\n",
      " - 9s - loss: 0.9295 - accuracy: 0.7538 - precision: 0.7505 - recall: 0.7605 - f1: 0.7554 - val_loss: 0.5203 - val_accuracy: 0.7981 - val_precision: 0.8060 - val_recall: 0.7740 - val_f1: 0.7896\n",
      "Epoch 14/100\n",
      " - 9s - loss: 0.8729 - accuracy: 0.7947 - precision: 0.7906 - recall: 0.8035 - f1: 0.7969 - val_loss: 0.4678 - val_accuracy: 0.8325 - val_precision: 0.8348 - val_recall: 0.8171 - val_f1: 0.8259\n",
      "Epoch 15/100\n",
      " - 9s - loss: 0.8441 - accuracy: 0.8042 - precision: 0.8001 - recall: 0.8109 - f1: 0.8054 - val_loss: 0.5085 - val_accuracy: 0.7920 - val_precision: 0.8007 - val_recall: 0.7650 - val_f1: 0.7824\n",
      "Epoch 16/100\n",
      " - 9s - loss: 0.8133 - accuracy: 0.8105 - precision: 0.8051 - recall: 0.8209 - f1: 0.8129 - val_loss: 0.4442 - val_accuracy: 0.8409 - val_precision: 0.8443 - val_recall: 0.8235 - val_f1: 0.8338\n",
      "Epoch 17/100\n",
      " - 9s - loss: 0.7747 - accuracy: 0.8237 - precision: 0.8189 - recall: 0.8314 - f1: 0.8250 - val_loss: 0.4860 - val_accuracy: 0.8033 - val_precision: 0.8092 - val_recall: 0.7808 - val_f1: 0.7947\n",
      "Epoch 18/100\n",
      " - 9s - loss: 0.7300 - accuracy: 0.8426 - precision: 0.8378 - recall: 0.8503 - f1: 0.8439 - val_loss: 0.4399 - val_accuracy: 0.8388 - val_precision: 0.8435 - val_recall: 0.8180 - val_f1: 0.8305\n",
      "Epoch 19/100\n",
      " - 9s - loss: 0.7080 - accuracy: 0.8432 - precision: 0.8416 - recall: 0.8445 - f1: 0.8430 - val_loss: 0.4486 - val_accuracy: 0.8267 - val_precision: 0.8350 - val_recall: 0.8007 - val_f1: 0.8174\n",
      "Epoch 20/100\n",
      " - 9s - loss: 0.6564 - accuracy: 0.8693 - precision: 0.8658 - recall: 0.8738 - f1: 0.8697 - val_loss: 0.4326 - val_accuracy: 0.8314 - val_precision: 0.8348 - val_recall: 0.8109 - val_f1: 0.8226\n",
      "Epoch 21/100\n",
      " - 9s - loss: 0.6365 - accuracy: 0.8708 - precision: 0.8687 - recall: 0.8749 - f1: 0.8717 - val_loss: 0.4044 - val_accuracy: 0.8501 - val_precision: 0.8562 - val_recall: 0.8274 - val_f1: 0.8415\n",
      "Epoch 22/100\n",
      " - 9s - loss: 0.6150 - accuracy: 0.8752 - precision: 0.8727 - recall: 0.8776 - f1: 0.8752 - val_loss: 0.4372 - val_accuracy: 0.8227 - val_precision: 0.8265 - val_recall: 0.8037 - val_f1: 0.8149\n",
      "Epoch 23/100\n",
      " - 9s - loss: 0.5830 - accuracy: 0.8865 - precision: 0.8843 - recall: 0.8895 - f1: 0.8868 - val_loss: 0.3860 - val_accuracy: 0.8566 - val_precision: 0.8572 - val_recall: 0.8394 - val_f1: 0.8482\n",
      "Epoch 24/100\n",
      " - 9s - loss: 0.5581 - accuracy: 0.8932 - precision: 0.8905 - recall: 0.8969 - f1: 0.8937 - val_loss: 0.3618 - val_accuracy: 0.8771 - val_precision: 0.8757 - val_recall: 0.8647 - val_f1: 0.8701\n",
      "Epoch 25/100\n",
      " - 9s - loss: 0.5282 - accuracy: 0.9022 - precision: 0.9001 - recall: 0.9042 - f1: 0.9021 - val_loss: 0.4247 - val_accuracy: 0.8251 - val_precision: 0.8292 - val_recall: 0.8084 - val_f1: 0.8186\n",
      "Epoch 26/100\n",
      " - 9s - loss: 0.5074 - accuracy: 0.9035 - precision: 0.9019 - recall: 0.9061 - f1: 0.9040 - val_loss: 0.3489 - val_accuracy: 0.8810 - val_precision: 0.8783 - val_recall: 0.8691 - val_f1: 0.8737\n",
      "Epoch 27/100\n",
      " - 9s - loss: 0.4720 - accuracy: 0.9163 - precision: 0.9120 - recall: 0.9209 - f1: 0.9164 - val_loss: 0.3683 - val_accuracy: 0.8619 - val_precision: 0.8598 - val_recall: 0.8479 - val_f1: 0.8538\n",
      "Epoch 28/100\n",
      " - 9s - loss: 0.4442 - accuracy: 0.9257 - precision: 0.9247 - recall: 0.9273 - f1: 0.9259 - val_loss: 0.3589 - val_accuracy: 0.8687 - val_precision: 0.8671 - val_recall: 0.8542 - val_f1: 0.8606\n",
      "Epoch 29/100\n",
      " - 9s - loss: 0.4290 - accuracy: 0.9281 - precision: 0.9274 - recall: 0.9295 - f1: 0.9284 - val_loss: 0.3145 - val_accuracy: 0.8971 - val_precision: 0.8935 - val_recall: 0.8905 - val_f1: 0.8920\n",
      "Epoch 30/100\n",
      " - 9s - loss: 0.4120 - accuracy: 0.9308 - precision: 0.9272 - recall: 0.9348 - f1: 0.9309 - val_loss: 0.4378 - val_accuracy: 0.8154 - val_precision: 0.8168 - val_recall: 0.8022 - val_f1: 0.8094\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.3995 - accuracy: 0.9345 - precision: 0.9351 - recall: 0.9345 - f1: 0.9348 - val_loss: 0.3291 - val_accuracy: 0.8866 - val_precision: 0.8828 - val_recall: 0.8788 - val_f1: 0.8808\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.3814 - accuracy: 0.9355 - precision: 0.9339 - recall: 0.9376 - f1: 0.9357 - val_loss: 0.3319 - val_accuracy: 0.8860 - val_precision: 0.8823 - val_recall: 0.8783 - val_f1: 0.8803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      " - 3s - loss: 0.3465 - accuracy: 0.9498 - precision: 0.9484 - recall: 0.9515 - f1: 0.9499 - val_loss: 0.3276 - val_accuracy: 0.8860 - val_precision: 0.8831 - val_recall: 0.8774 - val_f1: 0.8802\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.3391 - accuracy: 0.9512 - precision: 0.9503 - recall: 0.9522 - f1: 0.9513 - val_loss: 0.3150 - val_accuracy: 0.8957 - val_precision: 0.8918 - val_recall: 0.8882 - val_f1: 0.8900\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.3216 - accuracy: 0.9522 - precision: 0.9513 - recall: 0.9535 - f1: 0.9524 - val_loss: 0.3188 - val_accuracy: 0.8921 - val_precision: 0.8888 - val_recall: 0.8826 - val_f1: 0.8857\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.3038 - accuracy: 0.9561 - precision: 0.9547 - recall: 0.9576 - f1: 0.9561 - val_loss: 0.3234 - val_accuracy: 0.8892 - val_precision: 0.8850 - val_recall: 0.8822 - val_f1: 0.8836\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.2934 - accuracy: 0.9588 - precision: 0.9578 - recall: 0.9604 - f1: 0.9591 - val_loss: 0.3136 - val_accuracy: 0.8968 - val_precision: 0.8932 - val_recall: 0.8887 - val_f1: 0.8909\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.2711 - accuracy: 0.9613 - precision: 0.9606 - recall: 0.9623 - f1: 0.9615 - val_loss: 0.3076 - val_accuracy: 0.9020 - val_precision: 0.8963 - val_recall: 0.8972 - val_f1: 0.8967\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.2686 - accuracy: 0.9639 - precision: 0.9634 - recall: 0.9648 - f1: 0.9641 - val_loss: 0.3151 - val_accuracy: 0.8971 - val_precision: 0.8932 - val_recall: 0.8892 - val_f1: 0.8912\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.2495 - accuracy: 0.9700 - precision: 0.9699 - recall: 0.9705 - f1: 0.9702 - val_loss: 0.3115 - val_accuracy: 0.8981 - val_precision: 0.8934 - val_recall: 0.8912 - val_f1: 0.8923\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.2424 - accuracy: 0.9694 - precision: 0.9676 - recall: 0.9711 - f1: 0.9693 - val_loss: 0.3288 - val_accuracy: 0.8839 - val_precision: 0.8788 - val_recall: 0.8762 - val_f1: 0.8775\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.2370 - accuracy: 0.9693 - precision: 0.9685 - recall: 0.9703 - f1: 0.9694 - val_loss: 0.3111 - val_accuracy: 0.9020 - val_precision: 0.8973 - val_recall: 0.8946 - val_f1: 0.8959\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.2359 - accuracy: 0.9699 - precision: 0.9691 - recall: 0.9704 - f1: 0.9697 - val_loss: 0.3110 - val_accuracy: 0.9034 - val_precision: 0.8975 - val_recall: 0.8970 - val_f1: 0.8973\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.2216 - accuracy: 0.9749 - precision: 0.9744 - recall: 0.9757 - f1: 0.9751 - val_loss: 0.3085 - val_accuracy: 0.9055 - val_precision: 0.9010 - val_recall: 0.8993 - val_f1: 0.9001\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.2088 - accuracy: 0.9758 - precision: 0.9748 - recall: 0.9767 - f1: 0.9758 - val_loss: 0.3229 - val_accuracy: 0.8918 - val_precision: 0.8871 - val_recall: 0.8853 - val_f1: 0.8862\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.2016 - accuracy: 0.9782 - precision: 0.9779 - recall: 0.9786 - f1: 0.9783 - val_loss: 0.3122 - val_accuracy: 0.9041 - val_precision: 0.8992 - val_recall: 0.8988 - val_f1: 0.8990\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.1897 - accuracy: 0.9766 - precision: 0.9758 - recall: 0.9776 - f1: 0.9767 - val_loss: 0.3126 - val_accuracy: 0.9041 - val_precision: 0.8990 - val_recall: 0.8976 - val_f1: 0.8983\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.1833 - accuracy: 0.9802 - precision: 0.9799 - recall: 0.9808 - f1: 0.9803 - val_loss: 0.3136 - val_accuracy: 0.9026 - val_precision: 0.8975 - val_recall: 0.8962 - val_f1: 0.8968\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.1855 - accuracy: 0.9794 - precision: 0.9798 - recall: 0.9790 - f1: 0.9794 - val_loss: 0.3147 - val_accuracy: 0.9044 - val_precision: 0.8996 - val_recall: 0.8988 - val_f1: 0.8992\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.1739 - accuracy: 0.9825 - precision: 0.9820 - recall: 0.9828 - f1: 0.9824 - val_loss: 0.3186 - val_accuracy: 0.9041 - val_precision: 0.8990 - val_recall: 0.8981 - val_f1: 0.8986\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.1731 - accuracy: 0.9811 - precision: 0.9803 - recall: 0.9819 - f1: 0.9811 - val_loss: 0.3175 - val_accuracy: 0.9039 - val_precision: 0.8981 - val_recall: 0.8981 - val_f1: 0.8981\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.1784 - accuracy: 0.9822 - precision: 0.9821 - recall: 0.9825 - f1: 0.9823 - val_loss: 0.3183 - val_accuracy: 0.9039 - val_precision: 0.8992 - val_recall: 0.8983 - val_f1: 0.8987\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.1668 - accuracy: 0.9835 - precision: 0.9830 - recall: 0.9838 - f1: 0.9834 - val_loss: 0.3182 - val_accuracy: 0.9041 - val_precision: 0.8990 - val_recall: 0.8976 - val_f1: 0.8983\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.1646 - accuracy: 0.9842 - precision: 0.9843 - recall: 0.9839 - f1: 0.9841 - val_loss: 0.3234 - val_accuracy: 0.9060 - val_precision: 0.8999 - val_recall: 0.9017 - val_f1: 0.9008\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.1494 - accuracy: 0.9863 - precision: 0.9860 - recall: 0.9866 - f1: 0.9863 - val_loss: 0.3228 - val_accuracy: 0.9023 - val_precision: 0.8977 - val_recall: 0.8946 - val_f1: 0.8961\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1516 - accuracy: 0.9856 - precision: 0.9852 - recall: 0.9858 - f1: 0.9855 - val_loss: 0.3247 - val_accuracy: 0.9057 - val_precision: 0.9001 - val_recall: 0.9001 - val_f1: 0.9001\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.1466 - accuracy: 0.9880 - precision: 0.9881 - recall: 0.9878 - f1: 0.9879 - val_loss: 0.3265 - val_accuracy: 0.9013 - val_precision: 0.8967 - val_recall: 0.8936 - val_f1: 0.8952\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.1446 - accuracy: 0.9868 - precision: 0.9867 - recall: 0.9871 - f1: 0.9869 - val_loss: 0.3324 - val_accuracy: 0.9055 - val_precision: 0.9002 - val_recall: 0.9002 - val_f1: 0.9002\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.1374 - accuracy: 0.9886 - precision: 0.9885 - recall: 0.9886 - f1: 0.9886 - val_loss: 0.3290 - val_accuracy: 0.9036 - val_precision: 0.8985 - val_recall: 0.8972 - val_f1: 0.8978\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.1359 - accuracy: 0.9885 - precision: 0.9888 - recall: 0.9882 - f1: 0.9885 - val_loss: 0.3303 - val_accuracy: 0.9049 - val_precision: 0.9000 - val_recall: 0.8986 - val_f1: 0.8993\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.1325 - accuracy: 0.9875 - precision: 0.9875 - recall: 0.9878 - f1: 0.9876 - val_loss: 0.3388 - val_accuracy: 0.9089 - val_precision: 0.9032 - val_recall: 0.9036 - val_f1: 0.9034\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.1341 - accuracy: 0.9884 - precision: 0.9885 - recall: 0.9885 - f1: 0.9885 - val_loss: 0.3292 - val_accuracy: 0.9044 - val_precision: 0.8980 - val_recall: 0.8980 - val_f1: 0.8980\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.1263 - accuracy: 0.9888 - precision: 0.9888 - recall: 0.9890 - f1: 0.9889 - val_loss: 0.3365 - val_accuracy: 0.9068 - val_precision: 0.9010 - val_recall: 0.9006 - val_f1: 0.9008\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1236 - accuracy: 0.9889 - precision: 0.9887 - recall: 0.9893 - f1: 0.9890 - val_loss: 0.3393 - val_accuracy: 0.9081 - val_precision: 0.9033 - val_recall: 0.9011 - val_f1: 0.9022\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.1267 - accuracy: 0.9901 - precision: 0.9903 - recall: 0.9901 - f1: 0.9902 - val_loss: 0.3448 - val_accuracy: 0.9107 - val_precision: 0.9043 - val_recall: 0.9061 - val_f1: 0.9052\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.1211 - accuracy: 0.9897 - precision: 0.9892 - recall: 0.9901 - f1: 0.9896 - val_loss: 0.3374 - val_accuracy: 0.9044 - val_precision: 0.8988 - val_recall: 0.8970 - val_f1: 0.8979\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.1190 - accuracy: 0.9915 - precision: 0.9914 - recall: 0.9916 - f1: 0.9915 - val_loss: 0.3438 - val_accuracy: 0.9081 - val_precision: 0.9020 - val_recall: 0.9020 - val_f1: 0.9020\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.1156 - accuracy: 0.9909 - precision: 0.9906 - recall: 0.9914 - f1: 0.9910 - val_loss: 0.3456 - val_accuracy: 0.9086 - val_precision: 0.9036 - val_recall: 0.9027 - val_f1: 0.9031\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.1140 - accuracy: 0.9926 - precision: 0.9926 - recall: 0.9927 - f1: 0.9926 - val_loss: 0.3587 - val_accuracy: 0.9128 - val_precision: 0.9075 - val_recall: 0.9066 - val_f1: 0.9070\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.1120 - accuracy: 0.9915 - precision: 0.9915 - recall: 0.9912 - f1: 0.9914 - val_loss: 0.3465 - val_accuracy: 0.9091 - val_precision: 0.9040 - val_recall: 0.9032 - val_f1: 0.9036\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.1078 - accuracy: 0.9924 - precision: 0.9925 - recall: 0.9923 - f1: 0.9924 - val_loss: 0.3631 - val_accuracy: 0.9131 - val_precision: 0.9075 - val_recall: 0.9071 - val_f1: 0.9073\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.1151 - accuracy: 0.9903 - precision: 0.9900 - recall: 0.9906 - f1: 0.9903 - val_loss: 0.3408 - val_accuracy: 0.9015 - val_precision: 0.8959 - val_recall: 0.8946 - val_f1: 0.8952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      " - 3s - loss: 0.1114 - accuracy: 0.9922 - precision: 0.9920 - recall: 0.9924 - f1: 0.9922 - val_loss: 0.3535 - val_accuracy: 0.9126 - val_precision: 0.9070 - val_recall: 0.9066 - val_f1: 0.9068\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.1035 - accuracy: 0.9935 - precision: 0.9937 - recall: 0.9934 - f1: 0.9935 - val_loss: 0.3638 - val_accuracy: 0.9133 - val_precision: 0.9075 - val_recall: 0.9075 - val_f1: 0.9075\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.1023 - accuracy: 0.9923 - precision: 0.9922 - recall: 0.9922 - f1: 0.9922 - val_loss: 0.3558 - val_accuracy: 0.9115 - val_precision: 0.9061 - val_recall: 0.9056 - val_f1: 0.9058\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.1018 - accuracy: 0.9924 - precision: 0.9923 - recall: 0.9926 - f1: 0.9924 - val_loss: 0.3656 - val_accuracy: 0.9128 - val_precision: 0.9071 - val_recall: 0.9071 - val_f1: 0.9071\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.0980 - accuracy: 0.9935 - precision: 0.9935 - recall: 0.9934 - f1: 0.9935 - val_loss: 0.3572 - val_accuracy: 0.9099 - val_precision: 0.9040 - val_recall: 0.9035 - val_f1: 0.9037\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.0977 - accuracy: 0.9936 - precision: 0.9936 - recall: 0.9937 - f1: 0.9937 - val_loss: 0.3557 - val_accuracy: 0.9086 - val_precision: 0.9029 - val_recall: 0.9020 - val_f1: 0.9025\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.0957 - accuracy: 0.9930 - precision: 0.9928 - recall: 0.9931 - f1: 0.9929 - val_loss: 0.3751 - val_accuracy: 0.9126 - val_precision: 0.9066 - val_recall: 0.9071 - val_f1: 0.9068\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.0969 - accuracy: 0.9934 - precision: 0.9932 - recall: 0.9935 - f1: 0.9934 - val_loss: 0.3802 - val_accuracy: 0.9115 - val_precision: 0.9056 - val_recall: 0.9061 - val_f1: 0.9059\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.1054 - accuracy: 0.9917 - precision: 0.9918 - recall: 0.9918 - f1: 0.9918 - val_loss: 0.3526 - val_accuracy: 0.9086 - val_precision: 0.9032 - val_recall: 0.9009 - val_f1: 0.9020\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.0915 - accuracy: 0.9946 - precision: 0.9945 - recall: 0.9948 - f1: 0.9947 - val_loss: 0.3631 - val_accuracy: 0.9102 - val_precision: 0.9046 - val_recall: 0.9046 - val_f1: 0.9046\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.0906 - accuracy: 0.9941 - precision: 0.9941 - recall: 0.9941 - f1: 0.9941 - val_loss: 0.3593 - val_accuracy: 0.9102 - val_precision: 0.9048 - val_recall: 0.9030 - val_f1: 0.9039\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.0950 - accuracy: 0.9936 - precision: 0.9936 - recall: 0.9937 - f1: 0.9936 - val_loss: 0.3850 - val_accuracy: 0.9133 - val_precision: 0.9071 - val_recall: 0.9080 - val_f1: 0.9076\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.0928 - accuracy: 0.9945 - precision: 0.9947 - recall: 0.9945 - f1: 0.9946 - val_loss: 0.3551 - val_accuracy: 0.9044 - val_precision: 0.8976 - val_recall: 0.8985 - val_f1: 0.8980\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.0923 - accuracy: 0.9942 - precision: 0.9942 - recall: 0.9942 - f1: 0.9942 - val_loss: 0.3717 - val_accuracy: 0.9112 - val_precision: 0.9063 - val_recall: 0.9040 - val_f1: 0.9051\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.0877 - accuracy: 0.9947 - precision: 0.9945 - recall: 0.9949 - f1: 0.9947 - val_loss: 0.3741 - val_accuracy: 0.9110 - val_precision: 0.9064 - val_recall: 0.9041 - val_f1: 0.9052\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.0841 - accuracy: 0.9940 - precision: 0.9942 - recall: 0.9938 - f1: 0.9940 - val_loss: 0.3734 - val_accuracy: 0.9102 - val_precision: 0.9049 - val_recall: 0.9035 - val_f1: 0.9042\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.0868 - accuracy: 0.9944 - precision: 0.9947 - recall: 0.9941 - f1: 0.9944 - val_loss: 0.3883 - val_accuracy: 0.9128 - val_precision: 0.9067 - val_recall: 0.9075 - val_f1: 0.9071\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.0863 - accuracy: 0.9949 - precision: 0.9948 - recall: 0.9952 - f1: 0.9950 - val_loss: 0.3655 - val_accuracy: 0.9094 - val_precision: 0.9024 - val_recall: 0.9029 - val_f1: 0.9027\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.0862 - accuracy: 0.9959 - precision: 0.9958 - recall: 0.9960 - f1: 0.9959 - val_loss: 0.3781 - val_accuracy: 0.9123 - val_precision: 0.9070 - val_recall: 0.9061 - val_f1: 0.9065\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.0840 - accuracy: 0.9953 - precision: 0.9952 - recall: 0.9954 - f1: 0.9953 - val_loss: 0.3660 - val_accuracy: 0.9084 - val_precision: 0.9023 - val_recall: 0.9009 - val_f1: 0.9016\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.0816 - accuracy: 0.9951 - precision: 0.9952 - recall: 0.9952 - f1: 0.9952 - val_loss: 0.3887 - val_accuracy: 0.9128 - val_precision: 0.9079 - val_recall: 0.9061 - val_f1: 0.9070\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.0821 - accuracy: 0.9947 - precision: 0.9948 - recall: 0.9948 - f1: 0.9948 - val_loss: 0.3964 - val_accuracy: 0.9126 - val_precision: 0.9074 - val_recall: 0.9061 - val_f1: 0.9068\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.0881 - accuracy: 0.9945 - precision: 0.9947 - recall: 0.9945 - f1: 0.9946 - val_loss: 0.3653 - val_accuracy: 0.9044 - val_precision: 0.8980 - val_recall: 0.8980 - val_f1: 0.8980\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.0806 - accuracy: 0.9961 - precision: 0.9960 - recall: 0.9960 - f1: 0.9960 - val_loss: 0.3945 - val_accuracy: 0.9118 - val_precision: 0.9065 - val_recall: 0.9056 - val_f1: 0.9060\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.0820 - accuracy: 0.9952 - precision: 0.9953 - recall: 0.9951 - f1: 0.9952 - val_loss: 0.3778 - val_accuracy: 0.9115 - val_precision: 0.9053 - val_recall: 0.9043 - val_f1: 0.9048\n",
      "Epoch 98/100\n",
      " - 3s - loss: 0.0771 - accuracy: 0.9959 - precision: 0.9959 - recall: 0.9959 - f1: 0.9959 - val_loss: 0.3973 - val_accuracy: 0.9120 - val_precision: 0.9069 - val_recall: 0.9056 - val_f1: 0.9063\n",
      "Epoch 99/100\n",
      " - 3s - loss: 0.0777 - accuracy: 0.9957 - precision: 0.9956 - recall: 0.9958 - f1: 0.9957 - val_loss: 0.3788 - val_accuracy: 0.9105 - val_precision: 0.9047 - val_recall: 0.9029 - val_f1: 0.9038\n",
      "Epoch 100/100\n",
      " - 3s - loss: 0.0792 - accuracy: 0.9961 - precision: 0.9964 - recall: 0.9957 - f1: 0.9961 - val_loss: 0.4248 - val_accuracy: 0.9120 - val_precision: 0.9065 - val_recall: 0.9061 - val_f1: 0.9063\n",
      "Binaryclass-fullData-classweight-done\n"
     ]
    }
   ],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(0)\n",
    "\n",
    "DATA_PATH = '../input/'\n",
    "EMBEDDING_DIR = '../input/'\n",
    "\n",
    "MAX_NB_WORDS = 100000\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}'])\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.accuracies.append(logs.get('acc'))\n",
    "        \n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "        \n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "print('loading word embeddings...')\n",
    "embeddings_index = {}\n",
    "f = codecs.open('./Datasets/citation_data/wiki.simple.vec', encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('found %s word vectors' % len(embeddings_index))\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('./Datasets/citation_data' + '/final_data_citations_B.csv', sep=',', header=0,encoding = \"ISO-8859-1\")\n",
    "test_df = pd.read_csv('./Datasets/citation_data' + '/final_data_citations_B_test.csv', sep=',', header=0,encoding = \"ISO-8859-1\")\n",
    "test_df = test_df.fillna('_NA_')\n",
    "\n",
    "print(\"num train: \", train_df.shape[0])\n",
    "print(\"num test: \", test_df.shape[0])\n",
    "\n",
    "label_names = [\"positional\", \"essential\"]\n",
    "y_train = train_df[label_names].values\n",
    "\n",
    "#visualize word distribution\n",
    "train_df['doc_len'] = train_df['text'].apply(lambda words: len(words.split(\" \")))\n",
    "max_seq_len = np.round(train_df['doc_len'].mean() + train_df['doc_len'].std()).astype(int)\n",
    "#print(\"####################################################\")\n",
    "#print(max_seq_len)\n",
    "#==============================================================================\n",
    "# sns.distplot(train_df['doc_len'], hist=True, kde=True, color='b', label='doc len')\n",
    "# print(\"####################################################\")\n",
    "# plt.axvline(x=max_seq_len, color='k', linestyle='--', label='max len')\n",
    "# plt.title('comment length'); plt.legend()\n",
    "# plt.show()\n",
    "#==============================================================================\n",
    "raw_docs_train = train_df['text'].tolist()\n",
    "raw_docs_test = test_df['text'].tolist() \n",
    "num_classes = len(label_names)\n",
    "\n",
    "print(\"pre-processing train data...\")\n",
    "processed_docs_train = []\n",
    "for doc in tqdm(raw_docs_train):\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    processed_docs_train.append(\" \".join(filtered))\n",
    "#end for\n",
    "\n",
    "processed_docs_test = []\n",
    "for doc in tqdm(raw_docs_test):\n",
    "    tokens = tokenizer.tokenize(doc)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    processed_docs_test.append(\" \".join(filtered))\n",
    "#end for\n",
    "\n",
    "print(\"tokenizing input data...\")\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(processed_docs_train + processed_docs_test)  #leaky\n",
    "word_seq_train = tokenizer.texts_to_sequences(processed_docs_train)\n",
    "word_seq_test = tokenizer.texts_to_sequences(processed_docs_test)\n",
    "word_index = tokenizer.word_index\n",
    "print(\"dictionary size: \", len(word_index))\n",
    "\n",
    "#pad sequences\n",
    "word_seq_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
    "word_seq_test = sequence.pad_sequences(word_seq_test, maxlen=max_seq_len)\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(word_seq_train, y_train, test_size=.2,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "#print (X_test)\n",
    "#print(\"########################\")\n",
    "#print(Y_test)\n",
    "\n",
    "batch_size = 256 \n",
    "num_epochs = 1 \n",
    "\n",
    "#model parameters\n",
    "num_filters = 64 \n",
    "embed_dim = 300 \n",
    "weight_decay = 1e-3\n",
    "\n",
    "#embedding matrix\n",
    "print('preparing embedding matrix...')\n",
    "words_not_found = []\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index)+2)\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        words_not_found.append(word)\n",
    "print('number of null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "\n",
    "print(\"sample words not found: \", np.random.choice(words_not_found, 10))\n",
    "\n",
    "print(\"training CNN ...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(nb_words, embed_dim,\n",
    "          weights=[embedding_matrix], input_length=max_seq_len, trainable=False))\n",
    "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(num_filters, 7, activation='relu', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "\n",
    "class_weight = {0: 1,\n",
    "                1: 9}\n",
    "#class_weight=class_weight\n",
    "history = LossHistory()\n",
    "time_callback = TimeHistory()\n",
    "#metrics = Metrics()\n",
    "#keras.optimizers.Adam(lr=0.001)\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "#, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',precision,recall, f1])\n",
    "model.summary()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
    "callbacks_list = [early_stopping]\n",
    "pandas.DataFrame( model.fit(X_train, Y_train, validation_data=(X_test, Y_test), \n",
    "                                  batch_size=256,class_weight=class_weight, epochs=100, shuffle=True, verbose=2, callbacks=[history,time_callback]).history).to_csv(\"fullData-ClassWeight0.5-Adam_B_001.csv\")\n",
    "\n",
    "print(\"Binaryclass-fullData-classweight-done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9a3c37f89276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m pandas.DataFrame(model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=30,\n\u001b[0m\u001b[0;32m      3\u001b[0m           epochs=100, shuffle=True, callbacks=[earlystop_cb, check_cb, history]).history).to_csv(\"history.csv\")\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# ==============================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# # ==============================================================================\n",
    "# pandas.DataFrame(model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=30,\n",
    "#           epochs=100, shuffle=True, callbacks=[earlystop_cb, check_cb, history]).history).to_csv(\"history.csv\")\n",
    "# # ==============================================================================\n",
    "# # ==============================================================================\n",
    "# # ==============================================================================\n",
    "# y_test = model.predict(word_seq_test)\n",
    "# submission_df = pd.DataFrame(columns=['id'] + label_names)\n",
    "# submission_df['id'] = test_df['id'].values \n",
    "# submission_df[label_names] = y_test \n",
    "# submission_df.to_csv(\"./cnn_fasttext_submission.csv\", index=False)\n",
    "# plt.figure()\n",
    "# # ==============================================================================\n",
    "# # ==============================================================================\n",
    "# # ==============================================================================\n",
    "# plt.plot(hist.history['loss'], lw=2.0, color='b', label='train')\n",
    "# plt.plot(hist.history['val_loss'], lw=2.0, color='r', label='val')\n",
    "# plt.title('CNN sentiment')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Cross-Entropy Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "# plt.figure()\n",
    "# plt.plot(hist.history['acc'], lw=2.0, color='b', label='train')\n",
    "# plt.plot(hist.history['val_acc'], lw=2.0, color='r', label='val')\n",
    "# plt.title('CNN sentiment')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()\n",
    "# # ==============================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Metrics\n",
    "commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# class Metrics(keras.callbacks.Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.confusion = []\n",
    "#         self.precision = []\n",
    "#         self.recall = []\n",
    "#         self.f1s = []\n",
    "#         self.kappa = []\n",
    "#         self.auc = []\n",
    "# \n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#       score = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "#       predict = np.round(np.asarray(self.model.predict(self.validation_data[0])))\n",
    "#       predict2 = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "#       #print(\"#######y_predict2s#####\")\n",
    "#       #print(predict2)\n",
    "#       #print(\"#######y_predict#####\")\n",
    "#       #print(predict)\n",
    "#       targ = self.validation_data[1]\n",
    "#       #print(\"#######targ#####\")\n",
    "#       #print(targ)\n",
    "#       y_test_non_category = [ np.argmax(t) for t in targ ]\n",
    "#       y_predict_non_category = [ np.argmax(t) for t in predict ]\n",
    "#       y_predict_non_category2 = [ np.amax(t) for t in predict2 ]\n",
    "#       #print(\"#######y_predict_non_category2#####\")\n",
    "#       #print(y_predict_non_category2)\n",
    "#       #print(\"#######y_test_non_category#####\")\n",
    "#       #print(y_test_non_category)\n",
    "#       conf_mat = confusion_matrix(y_test_non_category, y_predict_non_category)\n",
    "#       print(\"########confusion_matrics########\")\n",
    "#       print(conf_mat)\n",
    "#         #self.auc.append(sklm.roc_auc_score(targ, score))\n",
    "# #==============================================================================\n",
    "# #       self.confusion.append(confusion_matrix(y_test_non_category, y_predict_non_category))\n",
    "# #       print(\"confusion_matrics 2\")\n",
    "# #       print(self.confusion)\n",
    "# #       \n",
    "# #==============================================================================\n",
    "#       report = classification_report(y_test_non_category,  y_predict_non_category, target_names=label_names)\n",
    "#       print(\"########classification report########\")\n",
    "#       print(report) \n",
    "#       \n",
    "#       fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test_non_category,  y_predict_non_category)\n",
    "#       auc_keras = auc(fpr_keras, tpr_keras)\n",
    "#       print(\"########ROC##########\")\n",
    "#       print(auc_keras) \n",
    "#       #self.classification_report.append(classification_report(y_test_non_category,  y_predict_non_category, target_names=label_names))\n",
    "#       self.precision.append(precision_score(y_test_non_category, y_predict_non_category,average='weighted'))\n",
    "#       self.recall.append(recall_score(y_test_non_category, y_predict_non_category,average='weighted'))\n",
    "#       #auc_PRC = auc(self.recall, self.precision)\n",
    "# #==============================================================================\n",
    "#       precision1, recall1, thresholds1 = precision_recall_curve(y_test_non_category, y_predict_non_category)\n",
    "#       print(\"########PRC##########\")\n",
    "#       auc_PRC= auc(recall1, precision1)\n",
    "#       print(auc_PRC)\n",
    "# #==============================================================================\n",
    "#  # Compute ROC curve and ROC area for each class\n",
    "#       fpr = dict()\n",
    "#       tpr = dict()\n",
    "#       roc_auc = dict()\n",
    "#       n_classes=2\n",
    "#       for i in range(n_classes):\n",
    "#           fpr[i], tpr[i], _ = roc_curve(targ[:, i], predict[:, i])\n",
    "#           roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# \n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "#       fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(targ.ravel(), predict.ravel())\n",
    "#       roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# \n",
    "# # Compute macro-average ROC curve and ROC area\n",
    "# \n",
    "# # First aggregate all false positive rates\n",
    "#       all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "# \n",
    "# # Then interpolate all ROC curves at this points\n",
    "#       mean_tpr = np.zeros_like(all_fpr)\n",
    "#       for i in range(n_classes):\n",
    "#           mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "# \n",
    "# # Finally average it and compute AUC\n",
    "#       mean_tpr /= n_classes\n",
    "# \n",
    "#       fpr[\"macro\"] = all_fpr\n",
    "#       tpr[\"macro\"] = mean_tpr\n",
    "#       roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "#       print(\"########ROC_MAC##########\")\n",
    "#       print(roc_auc) \n",
    "#       n_classes=2\n",
    "#       precision = dict()\n",
    "#       recall = dict()\n",
    "#       average_precision = dict()\n",
    "#       for i in range(n_classes):\n",
    "#             precision[i], recall[i], _ = precision_recall_curve(targ[:, i],\n",
    "#                                                                 predict[:, i])\n",
    "#             average_precision[i] = average_precision_score(targ[:, i], predict[:, i])\n",
    "#         \n",
    "#         # A \"micro-average\": quantifying score on all classes jointly\n",
    "#       precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(targ.ravel(),\n",
    "#             predict.ravel())\n",
    "#       average_precision[\"macro\"] = average_precision_score(targ, predict,\n",
    "#                                                              average=\"macro\")\n",
    "#       average_precision[\"micro\"] = average_precision_score(targ, predict,\n",
    "#                                                              average=\"micro\")\n",
    "#       average_precision[\"weighted\"] = average_precision_score(targ, predict,\n",
    "#                                                              average=\"weighted\")\n",
    "#       print('Average precision score, Macro-averaged over all classes: {0:0.5f}' .format(average_precision[\"macro\"]))\n",
    "#       print('Average precision score, Micro-averaged over all classes: {0:0.5f}' .format(average_precision[\"micro\"]))\n",
    "#       print('Average precision score, Weighted-averaged over all classes: {0:0.5f}' .format(average_precision[\"weighted\"]))\n",
    "#       \n",
    "#       return\n",
    "#=============================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
